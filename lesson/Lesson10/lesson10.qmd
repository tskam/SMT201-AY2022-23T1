---
title: "Lesson 10: Applied Image Analysis for the Urban Environment"
author: "Dr. Kam Tin Seong<br/>Assoc. Professor of Information Systems"
institute: "School of Computing and Information Systems,<br/>Singapore Management University"
date: "2022-08-12 (updated: `r Sys.Date()`)"
css: "text.css"
format: 
  revealjs:
    width: 1600
    height: 900
editor: visual
---

## Content

-   Digital Image Analysis

-   Multi-spectral Classification

-   Image change detection

## Multi-spectral Classification

::: columns
::: {.column width="50%"}
The process of assigning individual pixels of an image to categories, generally on the basis of spectral reflectance characteristics. Two kinds of multi-spectral classifications.

Unsupervised Classification: Digital information extraction technique in which the computer assigns pixels to categories with no instructions from the operator. Also known as Isodata Classification.

Supervised Classification: Digital-information extraction technique in which the operator provides training-site information that the computer uses to assign pixels to categories
:::

::: {.column width="50%"}
![](img/image1.jpg)
:::
:::

## Unsupervised Classification

::: columns
::: {.column width="50%"}
-   The goal of unsupervised classification is to automatically segregate pixels of a remote sensing image into groups of similar spectral character.

-   Classification is done using one of several statistical routines generally called "clustering" where classes of pixels are created based on their shared spectral signatures.

-   Clusters are split and /or merged until further clustering doesn't improve the explanation of the variation in the scene.
:::

::: {.column width="50%"}
![](img/image2.jpg)
:::
:::

------------------------------------------------------------------------

### Unsupervised classification algirithm

-   Hierarchical clustering
-   k-means clustering
-   Self-organised Map (SOM)
-   fuzzy-clustering

------------------------------------------------------------------------

### k-means clustering

-   Partitioning clustering approach.

-   Each cluster is associated with a centroid (center point).

-   Each point is assigned to the cluster with the closest centroid.

-   Number of clusters, K, must be specified.

-   The basic algorithm is very simple

![](img/image3.jpg)

------------------------------------------------------------------------

### How the K-means algorithm works?

The clustering process starts by randomly assigning objects to a number of clusters. The objects are then successively reassigned to other clusters to minimize the within-cluster variation, which is basically the (squared) distance from each observation to the center of the associated cluster. If the reallocation of an object to another cluster decreases the within-cluster variation, this object is reassigned to that cluster.

![](img/image4.jpg){fig-align="center"}

------------------------------------------------------------------------

### ISODATA clustering algorithm

-   The ISODATA algorithm has some further refinements by splitting and merging of clusters (JENSEN, 1996).

    -   Clusters are merged if either the number of members (pixel) in a cluster is less than a certain threshold or if the centers of two clusters are closer than a certain threshold.

    -   Clusters are split into two different clusters if the cluster standard deviation exceeds a predefined value and the number of members (pixels) is twice the threshold for the minimum number of members.

-   The ISODATA algorithm is similar to the k-means algorithm with the distinct difference that the ISODATA algorithm allows for different number of clusters while the k-means assumes that the number of clusters is known a priori.

------------------------------------------------------------------------

### ISODATA Iteration

-   In ISODATA iterations, pixels assigned to clusters with closest spectral mean; mean recalculated; pixels reassigned.

![](img/image6.jpg){fig-align="center"}

-   Continues until maximum iterations or convergence threshold reached.

------------------------------------------------------------------------

### Clustering Parameters

::: columns
::: {.column width="50%"}
-   To perform ISODATA clustering; NTM
    -   N -- maximum number of clusters to be considered. Since each cluster is the basis for a class, this number becomes the maximum number of classes to be formed. The ISODATA process begins by determining N arbitrary cluster means. Some clusters with too few pixels can be eliminated, leaving less than N clusters.
    -   T -- a convergence threshold, which is the maximum percentage of pixels whose class values are allowed to be unchanged between iterations.
    -   M -- maximum number of iterations to be performed
:::

::: {.column width="50%"}
-   Number of clusters: 10 to 15 per desired land cover class.

-   Convergence threshold: percentage of pixels whose class values should not change between iterations; generally set to 95%.

-   Maximum number of iterations: ideally, the convergence threshold should be reached. Should set "reasonable" parameters so that convergence is reached before iterations run out.
:::
:::

------------------------------------------------------------------------

### Limitation of k-means clustering

k-means and ISODATA clustering work best for images with clusters that are spherical and that have the same variance. This is often not true for remote sensing images. For example, a cluster with "desert" pixels is compact/circular. A "forest" cluster, however, is usually more or less elongated/oval with a much larger variability compared to the "desert" cluster. While the "desert" cluster is usually very well detected by the k-means algorithm as one distinct cluster, the "forest" cluster is often split up into several smaller cluster. The way the "forest" cluster is split up can vary quite a bit for different starting values and is thus arbitrary.

![](img/image7.jpg){fig-align="center"}

## Supervised Classification

::: columns
::: {.column width="50%"}
Supervised training is closely controlled by the analyst. In this process, you select pixels that represent patterns or land cover features that you recognize, or that you can identify with help from other sources, such as aerial photos, ground truth data, or maps. Knowledge of the data, and of the classes desired, is required before classification.

By identifying patterns, you can instruct the computer system to identify pixels with similar characteristics. If the classification is accurate, the resulting classes represent the categories within the data that you originally identified.
:::

::: {.column width="50%"}
![](img/image8.jpg)
:::
:::

------------------------------------------------------------------------

### Accuracy assessment for classifications

The basic principle for all accuracy assessment is to compare estimates with reality, and to quantify the difference between the two.

-   In the context of remote sensing-based land cover classifications, the 'estimates' are the classes mapped for each pixel, and 'reality' is the actual land cover in the areas corresponding to each pixel.

------------------------------------------------------------------------

### The confusion matrix

A confusion matrix (or error matrix) is usually used as the quantitative method of characterising image classification accuracy. It is a table that shows correspondence between the classification result and a reference image. I.e., to create the confusion matrix we need the ground truth data, such as cartographic information, results of manually digitizing an image, field work/ground survey results recorded with a GPS-receiver.

![](img/image9.jpg){fig-align="center"}

------------------------------------------------------------------------

### User, producer, and overall accuracy

::: {style="font-size: 0.8em"}
-   The user's accuracy column shows false positives, or errors of commission, where pixels are incorrectly classified as a known class when they should have been classified as something different. User's accuracy is also referred to as Type 1 error. The data to compute this error rate is read from the rows of the table. The user's accuracy is calculated by dividing the total number of classified points that agree with the reference data by the total number of classified points for that class. The Total row shows the number of points that should have been identified as a given class, according to the reference data.
:::

![](img/image10.jpg){fig-align="center"}

------------------------------------------------------------------------

### User, producer, and overall accuracy

::: {style="font-size: 0.8em"}
-   The producer's accuracy column shows false negatives, or errors of omission. The producer's accuracy indicates how accurately the classification results meet the expectation of the creator. Producer's accuracy is also referred to as Type 2 error. The data to compute this error rate is read in the columns of the table. The producer's accuracy is calculated by dividing the total number of classified points that agree with reference data by the total number of reference points for that class. These values are false-negative values within the classified results. The Total column shows the number of points that were identified as a given class, according to the classified map.
:::

![](img/image11.jpg){fig-align="center"}

------------------------------------------------------------------------

### User, producer, and overall accuracy

::: {style="font-size: 0.8em"}
-   The **overall accuracy** answers the following question: 'What proportion of the map is correctly classified?', which can often be interpreted simply as 'how accurate is the map?'. Looking at the values in the diagonal of the confusion matrix in the confusion matrix below, these sum up to 49+40+59=148, out of a total 166 pixels in the validation data set. 148 out of 166 is 89.16%, so based on the validation data we estimate that 89.16% of the map is correctly classified.
:::

![](img/image12.jpg){fig-align="center"}

------------------------------------------------------------------------

### Kappa

::: columns
::: {.column width="50%"}
KAPPA analysis is a discrete multivariate technique used in accuracy assessments.

-   It yields a Khat statistic (an estimate of KAPPA) that is a measure of agreement or accuracy.

-   The Khat statistic is computed by using the formula below:

![](img/image14.jpg)
:::

::: {.column width="50%"}
Rating criteria of Kappa statistics

![](img/image15.jpg){width="589"}

![](img/image15.jpg){width="2" height="1"}
:::
:::

------------------------------------------------------------------------

### F1 Score

::: columns
::: {.column width="50%"}
-   The goal of a good image analysis is, of course, to have a large number of True Presences, and a small number of False Presences and a small number of False Negatives.

-   To quantify how well the image analysis succeeded in this, the value typically calculated is called the F1 score, which is calculated as:

![](img/image16a.jpg){fig-align="center" width="423"}
:::

::: {.column width="50%"}
![](img/image16.jpg)

-   The F1 score has the nice property of having values that range from 0 (worst) to 1 (best), which makes it easy to interpret.
:::
:::
